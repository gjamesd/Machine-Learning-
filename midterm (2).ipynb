{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "latex_metadata": {
      "author": "Andreas C. M\\\"ller",
      "title": "Machine Learning with Python"
    },
    "colab": {
      "name": "midterm.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-b9_7J4aY3Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "np.random.seed(seed=484)\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gqnti0jbauQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrm1xGX-ayqS",
        "colab_type": "code",
        "outputId": "d3ea0b8f-2341-4879-e7ed-fb5d5b6e56b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "noXAFkfkaY3j",
        "colab_type": "text"
      },
      "source": [
        "# Midterm Exam"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0BHPVQIaY3k",
        "colab_type": "text"
      },
      "source": [
        "Exam is open book, open note, and open Google. You are not allowed outside\n",
        "help from another person, however. All work, including coding, must be yours alone. Remember to turn in both the written portion and this coding portion. To complete this coding portion, supply the python code in the empty cells below, and execute the notebook. To get full credit, the completed notebook should be able to run top to bottom, producing the results asked for in the prompts below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7__y4b_aY3l",
        "colab_type": "text"
      },
      "source": [
        "This portion of the exam will take you through the steps of the supervised machine learning process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NSNovXyGaY3m",
        "colab_type": "text"
      },
      "source": [
        "## 1. Figure out your question"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ku1odr78aY3n",
        "colab_type": "text"
      },
      "source": [
        "The question you want to answer using machine learning is: Would two people with identical observed characteristics but different race be predicted to have their loan applications treated differently?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS5XgtriaY3o",
        "colab_type": "text"
      },
      "source": [
        "## 2. Obtain a labeled dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek0Op7MwaY3q",
        "colab_type": "text"
      },
      "source": [
        "Import the python library that is good for manipulating datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDzcHTJtaY3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "#import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpVhfR9UaY3u",
        "colab_type": "text"
      },
      "source": [
        "Accompanying the exam materials are a spreadsheet of mortgage loan applicants, 'mortgagedenials.csv' and a text file, 'variabledefs.txt' that explains each variable in the spreadsheet. Read in the data in the spreadsheet 'mortgagedenials.csv', print out the first few rows of data with the variable names, and print out the number of observations and variables in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ePuqAP8UaY3w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#vars = pd.read_csv(\"/content/drive/My Drive/variabledefs.txt\", delimiter=\"\\t\")\n",
        "#print(vars.columns)\n",
        "var = pd.read_csv(\"/content/drive/My Drive/variabledefs.txt\", \n",
        "                   sep = \"\\t\")\n",
        "#var.columns = [\"variable name\", \"description\"]\n",
        "mort = pd.read_csv(\"/content/drive/My Drive/mortgagedenials.csv\")\n",
        "\n",
        "### come back to this cell \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g48nCDUzaY3y",
        "colab_type": "text"
      },
      "source": [
        "Define a label (outcome) vector, $y$, to be an indicator for whether the individual's mortgage application was denied, and define a feature (regressor) matrix, $X$, to be all remaining columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DQYnzi-aY3z",
        "colab_type": "code",
        "outputId": "0f24c494-b10b-4016-e7ce-d85aecdaa63d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "#finding my y variable\n",
        "mort.head()\n",
        "#selecting it as y \n",
        "y = mort.deny\n",
        "#selecting other columns to be the columns used for the data set \n",
        "data = mort.drop(axis = 1, columns = \"deny\")\n",
        "data.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p_irat</th>\n",
              "      <th>black</th>\n",
              "      <th>hse_inc</th>\n",
              "      <th>loan_val</th>\n",
              "      <th>ccred</th>\n",
              "      <th>mcred</th>\n",
              "      <th>pubrec</th>\n",
              "      <th>denpmi</th>\n",
              "      <th>selfemp</th>\n",
              "      <th>single</th>\n",
              "      <th>hischl</th>\n",
              "      <th>probunmp</th>\n",
              "      <th>condo</th>\n",
              "      <th>ltv_med</th>\n",
              "      <th>ltv_high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.217</td>\n",
              "      <td>0</td>\n",
              "      <td>0.213</td>\n",
              "      <td>0.638889</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.260</td>\n",
              "      <td>0</td>\n",
              "      <td>0.220</td>\n",
              "      <td>0.945946</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.9</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.460</td>\n",
              "      <td>0</td>\n",
              "      <td>0.270</td>\n",
              "      <td>0.840000</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5.3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.490</td>\n",
              "      <td>0</td>\n",
              "      <td>0.270</td>\n",
              "      <td>0.199482</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3.2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.260</td>\n",
              "      <td>0</td>\n",
              "      <td>0.260</td>\n",
              "      <td>0.366667</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   p_irat  black  hse_inc  loan_val  ...  probunmp  condo  ltv_med  ltv_high\n",
              "0   0.217      0    0.213  0.638889  ...       3.2      0        0         0\n",
              "1   0.260      0    0.220  0.945946  ...       3.9      0        1         0\n",
              "2   0.460      0    0.270  0.840000  ...       5.3      0        1         0\n",
              "3   0.490      0    0.270  0.199482  ...       3.2      0        0         0\n",
              "4   0.260      0    0.260  0.366667  ...       4.3      0        0         0\n",
              "\n",
              "[5 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FyWHoVFaaY35",
        "colab_type": "text"
      },
      "source": [
        "## 3. Divide into training and set sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "glExFBoGaY36",
        "colab_type": "text"
      },
      "source": [
        "Import the python library that is good for randomly splitting datasets into training and test sets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5BgupRmaY37",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing library from sklearn \n",
        "from sklearn.model_selection import train_test_split, GridSearchCV"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLrv1mIBaY3-",
        "colab_type": "text"
      },
      "source": [
        "Now make a training and test feature matrix and a training and test label vector:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oFxEByRaY3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#splitting \n",
        "X_train, X_test, y_train, y_test = train_test_split(data, y,\n",
        "                                                   test_size = 0.33,\n",
        "                                                   random_state = 42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gEOx2WziaY4C",
        "colab_type": "text"
      },
      "source": [
        "## 4. Pick an appropriate method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu42VKG6aY4D",
        "colab_type": "text"
      },
      "source": [
        "Choose a method appropriate for classification and import its library:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NAq3_SuYaY4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "''' I am going to utilize a random forest classifier, this will give me a 0\n",
        "or 1 outcome based on if the person was denied or not''' \n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from collections import Counter\n",
        "from sklearn.metrics import f1_score, classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qefwsdDQaY4G",
        "colab_type": "text"
      },
      "source": [
        "## 5. Choose regularization parameters via cross-validation on the training set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B61g6wrXaY4H",
        "colab_type": "text"
      },
      "source": [
        "Search over a grid of values of the regularization parameters for the parameters that perform the best out of sample:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0y0qCphaY4I",
        "colab_type": "code",
        "outputId": "e151ff82-e8b1-42c2-dccc-2af6223550eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "#building a param dictionary with different tree depths, and number of trees\n",
        "#creating a dictionary with multiple options for the parameters, \n",
        "param_dict = {\"n_estimators\":[100,500,1000,2500],\n",
        "              \"max_depth\":[1,3,5,10]}\n",
        "            #   \"min_samples_split\":[6,8,10,12],\n",
        "            #   \"min_samples_leaf\":[4,5,6,7]}\n",
        "\n",
        "#creating a class object \n",
        "rf = RandomForestClassifier()  \n",
        "\n",
        "#creating the grid search to search over my parameters and find the best ones \n",
        "gs = GridSearchCV(rf, param_dict, scoring = \"f1_macro\", \n",
        "                  n_jobs = -1, verbose = 2)\n",
        "gs.fit(X_train, y_train)\n",
        "\n",
        "#printing the best parameters \n",
        "print(\"Best Params: {}\".format(gs.best_params_))\n",
        "\n",
        "#ok so looks like best params are max depth of 10 and number of tree 100 "
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   42.0s\n",
            "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  1.0min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best Params: {'max_depth': 10, 'n_estimators': 1000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRLhkYOjaY4L",
        "colab_type": "text"
      },
      "source": [
        "## 6. Fit model on whole training set using the cross-validated parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-0QZWRdaY4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rf.fit(X_train, y_train)\n",
        "forest_pred = rf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvHQRR3zaY4P",
        "colab_type": "text"
      },
      "source": [
        "## 7. Evaluate model by applying it to test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04vrY3VXaY4Q",
        "colab_type": "text"
      },
      "source": [
        "Compute and print out the \"score\" of the model applied to the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZbcQkX6FaY4R",
        "colab_type": "code",
        "outputId": "f0a9a2b9-7814-4850-d0b2-f8588d0f82dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, forest_pred))\n",
        "from sklearn.metrics import confusion_matrix\n",
        "y_pred = gs.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "#ok so I am vastly over fitting, my best parameters are max depth of 10 but\n",
        "#only 100 trees, so I'll go again, closer around that neighborhood to see if\n",
        "# i can improve, from the confusion matrix you can clearly see the missclasification \n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.92      0.98      0.95       697\n",
            "           1       0.68      0.29      0.41        89\n",
            "\n",
            "    accuracy                           0.90       786\n",
            "   macro avg       0.80      0.64      0.68       786\n",
            "weighted avg       0.89      0.90      0.89       786\n",
            "\n",
            "[[684  13]\n",
            " [ 61  28]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru1BH3HIrdP1",
        "colab_type": "code",
        "outputId": "3bb7e0a9-f6bf-43ce-a921-e6b4130261ec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "\"\"\"I want to see what happens if ai narrow my dictionary around my best params\n",
        "\"\"\"\n",
        "\n",
        "param_dict = {\"n_estimators\":[200, 300, 400, 500, 600],\n",
        "              \"max_depth\":[8, 10, 12, 14]}\n",
        "\n",
        "gs2 = GridSearchCV(rf, param_dict, scoring = \"f1_macro\", \n",
        "                  n_jobs = -1, verbose = 2)\n",
        "gs2.fit(X_train, y_train)\n",
        "\n",
        "#printing the best parameters \n",
        "print(\"Best Params: {}\".format(gs2.best_params_))\n",
        "\n",
        "\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred2 = rf.predict(X_test)\n",
        "print(\"Random Forest Classification Report:\")\n",
        "print(classification_report(y_test, y_pred2))\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "cm = confusion_matrix(y_test, y_pred2)\n",
        "print(cm)\n",
        "#this was slightly better in terms of f1, my confusion matrix is also here \n",
        "# showing that I am still mis classifying a lot "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   19.4s\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   33.9s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best Params: {'max_depth': 12, 'n_estimators': 300}\n",
            "Random Forest Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94       697\n",
            "           1       0.62      0.26      0.37        89\n",
            "\n",
            "    accuracy                           0.90       786\n",
            "   macro avg       0.77      0.62      0.65       786\n",
            "weighted avg       0.88      0.90      0.88       786\n",
            "\n",
            "[[683  14]\n",
            " [ 66  23]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0vN-fovKaY4U",
        "colab_type": "text"
      },
      "source": [
        "## 8. Repeat 4-7 for another method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkyzNea1aY4V",
        "colab_type": "text"
      },
      "source": [
        "Import the method's library, do cross validation to find tuning parameters, fit the model on the training data using the cross-validated tuning parameters, and compute (and report) the model's score on the test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6fQeqbQ2DFa",
        "colab_type": "code",
        "outputId": "87cfd163-be0a-40ec-b02b-9870aedb75f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "#before I begin, I want to see what the number of yes vs no is \n",
        "\n",
        "y.value_counts()\n",
        "#ok so i have 2095 yes and 285 = 2380 total \n",
        "#and only 11% of those are no, I might synthetically create some no data to\n",
        "#make it more even "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2095\n",
              "1     285\n",
              "Name: deny, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RiGkVardaY4W",
        "colab_type": "code",
        "outputId": "040ea61f-a87e-4891-ead3-5e48397187fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "#now we will use support vector machines to classify the data in our second attempt\n",
        "from sklearn.svm import SVC\n",
        "svc = SVC(kernel = \"linear\")\n",
        "\n",
        "#creating dictionary\n",
        "sv_params = {\"C\": [0.03, 0.06, .09, .12, 0.15], \n",
        "             #\"kernel\": ['linear'], \n",
        "             'gamma': [0.3, .6, .9, 1.2, 1.5]}\n",
        "\n",
        "\n",
        "gridsearch = GridSearchCV(svc, \n",
        "                          sv_params, \n",
        "                          scoring='f1')\n",
        "\n",
        "gridsearch.fit(X_train, y_train)\n",
        "print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
        "\n",
        "y_pred = gridsearch.predict(X_test)\n",
        "\n",
        "#getting accuracy metrics \n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Params: {'C': 0.09, 'gamma': 0.3}\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      1.00      0.95       697\n",
            "           1       1.00      0.15      0.25        89\n",
            "\n",
            "    accuracy                           0.90       786\n",
            "   macro avg       0.95      0.57      0.60       786\n",
            "weighted avg       0.91      0.90      0.87       786\n",
            "\n",
            "[[697   0]\n",
            " [ 76  13]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZPhqiSY75TsK",
        "colab_type": "code",
        "outputId": "85349864-1b0b-45a0-aa51-455651981a8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        }
      },
      "source": [
        "#repeating for polynomial kernel \n",
        "\n",
        "svc = SVC(kernel = \"poly\", degree = 2)\n",
        "sv_params = {\"C\": [0.03, 0.06, .09, .12, 0.15], \n",
        "             #\"kernel\": ['precomputed'],\n",
        "             'gamma': [0.3, .6, .9, 1.2, 1.5]}\n",
        "\n",
        "\n",
        "gridsearch = GridSearchCV(svc, \n",
        "                          sv_params, \n",
        "                          scoring='f1',\n",
        "                          cv = 3\n",
        "                          )\n",
        "\n",
        "gridsearch.fit(X_train, y_train)\n",
        "\n",
        "y_pred = gridsearch.predict(X_test)\n",
        "#print(\"Best Params: {}\".format(gridsearch.best_params_))\n",
        "#getting accuracy metrics \n",
        "from sklearn.metrics import f1_score, classification_report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "\n",
        "'''still mis classifying a lot.  Tips to help with over fitting:\n",
        "increase the amount of training data, maybe use k fold cross validation so that\n",
        "we maximize the amount of information.  also we can decraese the number of parameters\n",
        "and maybe synthetically create more rejection observations. We have almost 90 percent \n",
        "of the observations are yes got approved, so the computer is having a hard time\n",
        "because if it simply says, yes they got approved, its right 90% of the time. \n",
        "'''"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.98      0.94       697\n",
            "           1       0.61      0.28      0.38        89\n",
            "\n",
            "    accuracy                           0.90       786\n",
            "   macro avg       0.76      0.63      0.66       786\n",
            "weighted avg       0.88      0.90      0.88       786\n",
            "\n",
            "[[681  16]\n",
            " [ 64  25]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'still mis classifying a lot.  Tips to help with over fitting:\\nincrease the amount of training data, maybe use k fold cross validation so that\\nwe maximize the amount of information.  also we can decraese the number of parameters\\nand maybe synthetically create more rejection observations. We have almost 90 percent \\nof the observations are yes got approved, so the computer is having a hard time\\nbecause if it simply says, yes they got approved, its right 90% of the time. \\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_qXWE-QaY4Z",
        "colab_type": "text"
      },
      "source": [
        "## 9. Apply the chosen method to new observations for which we have no labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gOxSm4taY4a",
        "colab_type": "text"
      },
      "source": [
        "Fit the method you chose (based on performance on the test set) to your entire dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6q1KPIpaY4b",
        "colab_type": "code",
        "outputId": "aa009497-6c7d-44e9-e911-681a52507dbb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        }
      },
      "source": [
        "'''\n",
        "ok so my weighted average of precision and recall is my f1 score and that was \n",
        "highest in the random forest.  When I narrowed my scope around my best params \n",
        "i still got an f1 of .89.  So I will just go with the second model.'''\n",
        "\n",
        "\"\"\"I want to see what happens if ai narrow my dictionary around my best params\n",
        "\"\"\"\n",
        "#using the dictionary\n",
        "param_dict = {\"n_estimators\":[200, 300, 400, 500, 600],\n",
        "              \"max_depth\":[8, 10, 12, 14]}\n",
        "\n",
        "#grid searching \n",
        "gs2 = GridSearchCV(rf, param_dict, scoring = \"f1_macro\", \n",
        "                  n_jobs = -1, verbose = 2)\n",
        "#fitting on the search \n",
        "gs2.fit(data, y)\n",
        "#fitting on the model of choice \n",
        "rf.fit(data, y)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:   21.9s\n",
            "[Parallel(n_jobs=-1)]: Done  60 out of  60 | elapsed:   38.6s finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=10,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5S4YKPCPaY4d",
        "colab_type": "text"
      },
      "source": [
        "The spreadsheet 'newapplicants.csv' contains information on two new mortgage applicants, the first black, the second non-black, but who otherwise share identical characteristics, namely, they both have monthly debt-to-income and housing expenses to income ratio of .25, both have a loan to property value ratio of .951, both have a category 4 credit and mortgage score, neither has a public record of credit problems, neither was denied mortgage insurance, both are self-employed, both are single, neither graduated from high school, both have occupations with an industry unemployment rate of 9, and neither is purchasing a condo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Syrmd_yaY4d",
        "colab_type": "text"
      },
      "source": [
        "Read in the new applicant information and apply the chosen model to predict whether each applicant will be denied or not, and print out the predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "hide_input": false,
        "id": "tZx_KyUuaY4e",
        "colab_type": "code",
        "outputId": "f6fa77c8-d8e6-4328-b219-e6545a1058c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "test = pd.read_csv(\"/content/drive/My Drive/newapplicants.csv\")\n",
        "\n",
        "test.head()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>p_irat</th>\n",
              "      <th>black</th>\n",
              "      <th>hse_inc</th>\n",
              "      <th>loan_val</th>\n",
              "      <th>ccred</th>\n",
              "      <th>mcred</th>\n",
              "      <th>pubrec</th>\n",
              "      <th>denpmi</th>\n",
              "      <th>selfemp</th>\n",
              "      <th>single</th>\n",
              "      <th>hischl</th>\n",
              "      <th>probunmp</th>\n",
              "      <th>condo</th>\n",
              "      <th>ltv_med</th>\n",
              "      <th>ltv_high</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.25</td>\n",
              "      <td>1</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.951</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.25</td>\n",
              "      <td>0</td>\n",
              "      <td>0.25</td>\n",
              "      <td>0.951</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   p_irat  black  hse_inc  loan_val  ...  probunmp  condo  ltv_med  ltv_high\n",
              "0    0.25      1     0.25     0.951  ...         9      0        0         1\n",
              "1    0.25      0     0.25     0.951  ...         9      0        0         1\n",
              "\n",
              "[2 rows x 15 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3ScRVHstscC",
        "colab_type": "code",
        "outputId": "b7538687-d103-4d82-924c-1c21725606a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_pred =  rf.predict(test)\n",
        "print(test_pred)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuSW9cOHuO11",
        "colab_type": "code",
        "outputId": "e30d3c5c-9a81-4c16-c6fc-fe86c001f9ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "source": [
        "print(sum(data.black))\n",
        "print(data.shape)\n",
        "print(339/2380)\n",
        "print(sum(y))\n",
        "print(285/2380)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "339\n",
            "(2380, 15)\n",
            "0.14243697478991596\n",
            "285\n",
            "0.11974789915966387\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP1XPs2_aY4g",
        "colab_type": "text"
      },
      "source": [
        "Do the predictions differ between the black and non-black applicant, and what if anything does this suggest about the fairness of the mortgage application process?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZXBkaEraY4g",
        "colab_type": "text"
      },
      "source": [
        "type your answer in this cell\n",
        "NO"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soJk6KX_vC7i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}